syntax = "proto3";

package cognition;

option go_package = "github.com/GriffinCanCode/good-listener/backend/platform/pkg/pb";

// ============================================================================
// Error Handling - Cross-language error codes
// ============================================================================

// ErrorCode defines standardized error codes across Python, Go, and TypeScript.
// Use with gRPC status details for rich error propagation.
enum ErrorCode {
    ERROR_CODE_UNSPECIFIED = 0;
    
    // General errors (1-99)
    UNKNOWN = 1;
    INTERNAL = 2;
    INVALID_ARGUMENT = 3;
    NOT_FOUND = 4;
    UNAVAILABLE = 5;
    TIMEOUT = 6;
    CANCELLED = 7;
    
    // Audio domain (100-199)
    AUDIO_INVALID_FORMAT = 100;
    AUDIO_EMPTY_INPUT = 101;
    AUDIO_TRANSCRIPTION_FAILED = 102;
    AUDIO_VAD_FAILED = 103;
    AUDIO_DIARIZATION_FAILED = 104;
    AUDIO_MODEL_LOAD_FAILED = 105;
    
    // LLM domain (200-299)
    LLM_NOT_CONFIGURED = 200;
    LLM_API_ERROR = 201;
    LLM_RATE_LIMITED = 202;
    LLM_CONTEXT_TOO_LONG = 203;
    LLM_INVALID_RESPONSE = 204;
    
    // Memory domain (300-399)
    MEMORY_STORE_FAILED = 300;
    MEMORY_QUERY_FAILED = 301;
    MEMORY_POOL_EXHAUSTED = 302;
    MEMORY_INIT_FAILED = 303;
    
    // OCR domain (400-499)
    OCR_INIT_FAILED = 400;
    OCR_EXTRACT_FAILED = 401;
    OCR_INVALID_IMAGE = 402;
    
    // Config domain (500-599)
    CONFIG_INVALID = 500;
    CONFIG_MISSING = 501;
}

// ErrorDetail provides structured error information for client-side handling.
// Embed in gRPC status details using google.rpc.Status.details.
message ErrorDetail {
    ErrorCode code = 1;
    string message = 2;
    map<string, string> metadata = 3;  // Additional context (e.g., field names, limits)
}

// ============================================================================
// Transcription Service - Whisper STT
// ============================================================================

service TranscriptionService {
    // Transcribe audio bytes to text
    rpc Transcribe(TranscribeRequest) returns (TranscribeResponse);
    
    // Stream audio chunks for real-time transcription
    rpc StreamTranscribe(stream AudioChunk) returns (stream TranscriptSegment);
    
    // Diarize audio to identify speakers with timestamps
    rpc Diarize(DiarizeRequest) returns (DiarizeResponse);
}

message TranscribeRequest {
    bytes audio_data = 1;      // PCM float32 audio at 16kHz
    int32 sample_rate = 2;     // Sample rate (default 16000)
    string language = 3;       // Optional language hint
}

message TranscribeResponse {
    string text = 1;
    double confidence = 2;
    int64 duration_ms = 3;
}

message AudioChunk {
    bytes data = 1;            // PCM float32 audio chunk
    int64 timestamp_ns = 2;    // Nanosecond timestamp
    string device_id = 3;      // Source device identifier
}

message TranscriptSegment {
    string text = 1;
    string device_id = 2;
    int64 start_ns = 3;
    int64 end_ns = 4;
    bool is_final = 5;
}

message DiarizeRequest {
    bytes audio_data = 1;      // PCM float32 audio at 16kHz
    int32 sample_rate = 2;     // Sample rate (default 16000)
    int32 min_speakers = 3;    // Minimum expected speakers
    int32 max_speakers = 4;    // Maximum expected speakers (0 for auto)
}

message DiarizeResponse {
    repeated SpeakerSegment segments = 1;
}

message SpeakerSegment {
    string speaker = 1;        // Speaker label (e.g., "SPEAKER_00")
    double start_sec = 2;      // Start time in seconds
    double end_sec = 3;        // End time in seconds
}

// ============================================================================
// OCR Service - Text extraction from images
// ============================================================================

service OCRService {
    rpc ExtractText(OCRRequest) returns (OCRResponse);
}

message OCRRequest {
    bytes image_data = 1;      // JPEG or PNG encoded image
    string format = 2;         // "jpeg" or "png"
}

message OCRResponse {
    string text = 1;
    repeated BoundingBox boxes = 2;
}

message BoundingBox {
    int32 x1 = 1;
    int32 y1 = 2;
    int32 x2 = 3;
    int32 y2 = 4;
    string text = 5;
    float confidence = 6;
}

// ============================================================================
// LLM Service - Language model inference
// ============================================================================

service LLMService {
    // Streaming analysis response
    rpc Analyze(AnalyzeRequest) returns (stream AnalyzeChunk);
    
    // Check if text is a question
    rpc IsQuestion(IsQuestionRequest) returns (IsQuestionResponse);
    
    // Summarize transcript for context compression
    rpc SummarizeTranscript(SummarizeRequest) returns (SummarizeResponse);
}

message SummarizeRequest {
    string transcript = 1;     // Raw transcript text to summarize
    int32 max_length = 2;      // Target max length for summary (optional)
}

message SummarizeResponse {
    string summary = 1;
    int32 original_length = 2;
    int32 summary_length = 3;
}

message AnalyzeRequest {
    string context_text = 1;   // OCR/screen text
    string user_query = 2;     // User's question
    bytes image_data = 3;      // Optional screenshot (JPEG)
    string transcript = 4;     // Recent conversation transcript
}

message AnalyzeChunk {
    string content = 1;
    bool is_final = 2;
}

message IsQuestionRequest {
    string text = 1;
}

message IsQuestionResponse {
    bool is_question = 1;
}

// ============================================================================
// Memory Service - Vector storage and retrieval
// ============================================================================

service MemoryService {
    rpc Store(StoreRequest) returns (StoreResponse);
    rpc BatchStore(BatchStoreRequest) returns (BatchStoreResponse);
    rpc Query(QueryRequest) returns (QueryResponse);
    rpc Clear(ClearRequest) returns (ClearResponse);
}

message StoreRequest {
    string text = 1;
    string source = 2;         // "audio" or "screen"
    map<string, string> metadata = 3;
}

message StoreResponse {
    string id = 1;
    bool success = 2;
}

message BatchStoreRequest {
    repeated StoreRequest items = 1;
}

message BatchStoreResponse {
    repeated string ids = 1;
    int32 stored_count = 2;
}

message QueryRequest {
    string query_text = 1;
    int32 n_results = 2;
    string source_filter = 3;  // Optional: filter by source
}

message QueryResponse {
    repeated string documents = 1;
    repeated float scores = 2;
}

message ClearRequest {}

message ClearResponse {
    int32 deleted_count = 1;
}

// ============================================================================
// VAD Service - Voice Activity Detection
// ============================================================================

service VADService {
    rpc DetectSpeech(VADRequest) returns (VADResponse);
    rpc ResetState(ResetStateRequest) returns (ResetStateResponse);
}

message VADRequest {
    bytes audio_chunk = 1;     // 512 samples of float32 PCM
    int32 sample_rate = 2;
}

message VADResponse {
    float speech_probability = 1;
    bool is_speech = 2;
}

message ResetStateRequest {}

message ResetStateResponse {
    bool success = 1;
}

